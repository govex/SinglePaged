---
title: "The Toolkit"
bg: purple
color: white
fa-icon: tasks
---


### To use this toolkit, we assume you:
- Have some knowledge of data science concepts or experience with algorithms
- Largely understand your data

-------------------------
There are five documents which comprise the toolkit. Access them individually below, or **[download them all in a zip file](assets/ethicstoolkit.ai.zip) <i class=fa fa-file-archive-o"></i>**:

## Overview and Introduction
The **[overview section](assets/overview.pdf) <i class="fa fa-file-pdf-o"></i>** of the toolkit is comprised of level-setting background information that will be useful when traversing subsequent sections of the toolkit. We have outlined a few real-life scenarios where the toolkit might be applied, provided definitions, and more. For example, while we briefly touched upon machine learning in the previous module, the toolkit overview helps you understand more about the various types which exist, such as supervised learning, unsupervised learning, and so on.

## Part 1: Assess Algorithm Risk 
In **[Part 1](assets/part_1.pdf) <i class="fa fa-file-pdf-o"></i>** of the toolkit, there are six major steps (or questions) to help you and your stakeholders characterize an algorithm. Many of these steps have multiple components, but also include clear instructions on how to summarize those stages in order to complete the step. 

Since this document can be difficult to navigate, we have developed a **[worksheet for Part 1](assets/part_1_worksheet.pdf) <i class="fa fa-file-pdf-o"></i>**, designed to help you track your responses to the individual steps and how they are combined into overall risk values. It’s worth noting that although answering a series of questions seems simple, you will almost certainly need additional people to help - whether they are stakeholders, data analysts, information technology professionals, or representatives from a vendor that you are working with. Don’t expect to complete this part of the toolkit in just a few hours. Some of the steps will evoke considerable discussion.

## Part 2: Manage Algorithm Risk
Although it’s helpful to know how concerned you should be about various aspects of your algorithm, that’s really only half the battle. Although there may be a few cases where the risks are too severe to proceed, there are often ways to mitigate them. Using **[Part 2](assets/part_2.pdf) <i class="fa fa-file-pdf-o"></i>** of the toolkit, you identify specific techniques to help address the considerations you identified in Part 1. 

The results of Part 2 will be highly customized and specific to the factors you evaluated in part 1. Some of the recommendations can introduce significant burdens that are more appropriately addressed within large-scale programs, such as those that support the social safety net. It is not unusual to need executive and political support to be successful.

## Appendices
Although this isn’t specifically required reading in order to use the toolkit, the **[appendices](assets/appendices.pdf) <i class="fa fa-file-pdf-o"></i>** provide plenty of additional context and depth. The first appendix contains a list of in-depth questions to help you understand your data in more detail. The second provides additional background on bias and how easily it can arise.
